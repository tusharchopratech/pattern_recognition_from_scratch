{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets Description\n",
    "\n",
    "The UCI Machine Learning Repository is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms.\n",
    "\n",
    "Datasets are available on http://archive.ics.uci.edu/ml/datasets.html For this homework assignment, you need to download the datasets “glass” and “Tic-Tac-Toe Endgame” from the above link. The “glass” dataset is categorical and the “Tic-Tac-Toe” dataset is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 1**\n",
    "\n",
    "Design a C4.5 decision tree classifier to classify each dataset mentioned above. Report the accuracy based on the 10-times-10-fold cross validation approach (20% of training set as the validation set for every experiment). Report the mean accuracy and the variance of the accuracy for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: \n",
    "    def __init__(self, data): \n",
    "        self.data = data \n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self): \n",
    "        self.root_main = None\n",
    "        self.rules = []\n",
    "    \n",
    "    def build_tree(self, df, root=None, pointer=\"S\", counter=0):\n",
    "\n",
    "        # data preparations\n",
    "        if counter == 0:\n",
    "            global COLUMN_HEADERS, FEATURE_TYPES\n",
    "            COLUMN_HEADERS = df.columns\n",
    "            FEATURE_TYPES = determine_type_of_feature(df)\n",
    "            data = df.values\n",
    "        else:\n",
    "            data = df           \n",
    "\n",
    "        # base cases\n",
    "        if (check_purity(data)):\n",
    "            classification = classify_data(data)\n",
    "            node = Node(classification)\n",
    "            if pointer is \"L\":\n",
    "                root.left=node\n",
    "                root=node\n",
    "            if pointer is \"R\":\n",
    "                root.right=node\n",
    "                root=node\n",
    "            return \n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "\n",
    "            # helper functions \n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, potential_splits)\n",
    "            data_below, data_above = split_data(data, split_column, split_value)\n",
    "\n",
    "            # check for empty data\n",
    "            if len(data_below) == 0 or len(data_above) == 0:\n",
    "                classification = classify_data(data)\n",
    "                node = Node(classification)\n",
    "                if pointer is \"L\":\n",
    "                    root.left=node\n",
    "                    root=node\n",
    "                if pointer is \"R\":\n",
    "                    root.right=node\n",
    "                    root=node\n",
    "                return\n",
    "\n",
    "            # determine question\n",
    "            feature_name = COLUMN_HEADERS[split_column]\n",
    "            type_of_feature = FEATURE_TYPES[split_column]\n",
    "            if type_of_feature == \"continuous\":\n",
    "                question = \"{} <= {}\".format(feature_name, split_value)\n",
    "\n",
    "            # feature is categorical\n",
    "            else:\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "\n",
    "            # instantiate sub-tree\n",
    "            if pointer is \"S\":\n",
    "                root=Node(question)\n",
    "                self.root_main = root\n",
    "            else:\n",
    "    #             sub_tree = {question: []}\n",
    "\n",
    "                # find answers (recursion) \n",
    "                node = Node(question)\n",
    "                if pointer is \"L\":\n",
    "                    root.left=node   \n",
    "                    root=node\n",
    "\n",
    "                if pointer is \"R\":\n",
    "                    root.right=node\n",
    "                    root=node\n",
    "\n",
    "            self.build_tree(data_below, root, \"L\", counter)\n",
    "            self.build_tree(data_above, root, \"R\", counter)\n",
    "\n",
    "            return self.root_main\n",
    "         \n",
    "    def convert_tree_to_rules(self, path=[], pathLen=0, status=\"\"):\n",
    "        root = self.root_main\n",
    "        self.get_paths(root,path,pathLen,status)\n",
    "        ar = np.array(self.rules)\n",
    "        for i in range(len(self.rules)):\n",
    "            for j in range(len(self.rules[i])):\n",
    "                if \"R\" in self.rules[i][j]:\n",
    "                    feature_name, comparison_operator, value = self.rules[i][j-1].split(\" \")\n",
    "                    self.rules[i][j-1] = \"{} > {}\".format(feature_name, value) \n",
    "                self.rules[i][j]=self.rules[i][j].replace('R', '')\n",
    "                self.rules[i][j]=self.rules[i][j].replace('L', '')\n",
    "        return self.rules\n",
    "        \n",
    "    def printArray(self, ints, len): \n",
    "        array = []\n",
    "        for i in ints[0 : len]:\n",
    "            array.append(str(i))\n",
    "        self.rules.append(array)\n",
    "    \n",
    "    def get_paths(self, root, path, pathLen, status):\n",
    "\n",
    "        if root is None: \n",
    "            return\n",
    "\n",
    "        if(len(path) > pathLen):  \n",
    "            path[pathLen] = status+str(root.data) \n",
    "        else: \n",
    "            path.append(status+str(root.data))\n",
    "\n",
    "        pathLen = pathLen + 1\n",
    "\n",
    "        if root.left is None and root.right is None: \n",
    "            self.printArray(path, pathLen) \n",
    "        else: \n",
    "            self.get_paths(root.left, path, pathLen, \"L\") \n",
    "            self.get_paths(root.right, path, pathLen, \"R\") \n",
    "\n",
    "    def get_class_of_sample_from_rule(self, rule, sample):\n",
    "        \n",
    "        sample = [float(val) for val in sample]\n",
    "        sample_class = None\n",
    "        for i in range(len(rule)):\n",
    "            if i < len(rule) - 1:\n",
    "                feature_index, comparison_operator, value = rule[i].split(\" \")\n",
    "                if FEATURE_TYPES[int(feature_index)] == \"continuous\":\n",
    "                    if comparison_operator == \"<=\":\n",
    "                        if not sample[int(feature_index)] <= float(value):\n",
    "                            break\n",
    "                    elif comparison_operator == \">\":\n",
    "                        if not sample[int(feature_index)] > float(value):\n",
    "                            break\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                sample_class = rule[len(rule)-1]\n",
    "                \n",
    "        return sample_class\n",
    "            \n",
    "    def prune_rule(self, rule, validation_data):\n",
    "        \n",
    "        base_rule = rule\n",
    "        old_accuracy = 0\n",
    "        new_rule = rule\n",
    "        new_accuracy = 0.0\n",
    "        base_accuracy = 0\n",
    "        \n",
    "        flag = 1\n",
    "        for total_rule_elements in range(len(rule)-1, 2, -1):\n",
    "            \n",
    "            my_rule = rule[:total_rule_elements]\n",
    "            my_rule.append(rule[len(rule)-1])\n",
    "            accuracy = 0\n",
    "\n",
    "            for i in range(len(validation_data)):\n",
    "                predict_class = self.get_class_of_sample_from_rule(my_rule, validation_data[i])\n",
    "                if predict_class == str(validation_data[i][9]):\n",
    "                    accuracy +=1\n",
    "            if flag == 1:\n",
    "                base_accuracy = accuracy/len(validation_data)\n",
    "                old_accuracy=base_accuracy\n",
    "                new_accuracy=base_accuracy\n",
    "                new_rule = my_rule\n",
    "                flag=0\n",
    "            else:\n",
    "                new_accuracy = accuracy/len(validation_data)\n",
    "                if new_accuracy > old_accuracy:\n",
    "                    new_rule = my_rule\n",
    "                    old_accuracy = new_accuracy\n",
    "                if new_accuracy == 1.0:\n",
    "                    break\n",
    "                           \n",
    "        return base_rule, base_accuracy, new_rule, new_accuracy\n",
    "    \n",
    "    \n",
    "    def prune_tree(self):\n",
    "        self.convert_tree_to_rules()\n",
    "\n",
    "#         for rule in self.rules:\n",
    "#             print(rule)\n",
    "            \n",
    "        for i, rule in enumerate(self.rules):\n",
    "            rule_label = rule[len(rule)-1]\n",
    "            filtered_validation_data =validation_data.values[np.where(validation_data.values[:,-1] == float(rule_label))]\n",
    "            if len(filtered_validation_data)>0:\n",
    "                old_rule, old_accurcay, new_rule, new_accuracy = self.prune_rule(rule, filtered_validation_data)\n",
    "                new_rule = [new_accuracy] + new_rule\n",
    "                self.rules[i] = new_rule\n",
    "            \n",
    "        self.rules.sort(key=lambda x: x[0])\n",
    "        self.rules = self.rules[::-1]\n",
    "#         for rule in self.rules:\n",
    "#             print(rule)\n",
    "\n",
    "    \n",
    "    def get_rules(self): \n",
    "        self.rules = [val[1:] for val in self.rules]\n",
    "        return self.rules\n",
    "    \n",
    "    def predict_class(self, sample):\n",
    "        sample_class = None\n",
    "        for rule in self.rules:\n",
    "            sample_class = self.get_class_of_sample_from_rule(rule,sample)\n",
    "            if sample_class is not None:\n",
    "                break\n",
    "        return sample_class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train_test_k_fold_split(df, fold):\n",
    "    indices = df.index.tolist()\n",
    "    random.shuffle(indices)\n",
    "    low = int((fold/10)*len(indices))\n",
    "    high = int(((fold+1)/10)*len(indices))\n",
    "    test_indices=indices[low:high]\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_training_and_validation(df, division):\n",
    "    indices = df.index.tolist()\n",
    "    random.shuffle(indices)\n",
    "    validation_indices=indices[int((1-division)*len(indices)):]\n",
    "    validation_df = df.loc[validation_indices]\n",
    "    train_df = df.drop(validation_indices)\n",
    "    return train_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38095238095238093\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "df.columns = [i for i in range(len(df.columns))]\n",
    "\n",
    "\n",
    "train_df, test_df = train_test_k_fold_split(df, 1)\n",
    "train_data, validation_data=split_training_and_validation(train_df, 0.2)\n",
    "\n",
    "decision_tree = DecisionTree()\n",
    "\n",
    "tree_root = decision_tree.build_tree(train_data)\n",
    "decision_tree.prune_tree()\n",
    "rules = decision_tree.get_rules()\n",
    "\n",
    "# print(test_df)\n",
    "\n",
    "correct = 0\n",
    "for j in range(len(test_df)):\n",
    "    example = test_df.iloc[j]\n",
    "    if float(decision_tree.predict_class(example))==example[9]: correct+=1\n",
    "    \n",
    "print(correct/len(test_df))\n",
    "\n",
    "# for i in range(len(rules)):\n",
    "#     print(rules[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glass Mean Accuracy:  0.47597402597402594\n",
      "Glass Accucarcy Varianse:  0.040414769213470515\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data')df.columns = ['f'+str(i) for i in range(len(df.columns))]\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "\n",
    "my_accuracies = []\n",
    "sk_accuracies = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_df, test_df = train_test_k_fold_split(df, i)\n",
    "    tree = decision_tree_algorithm(train_df)\n",
    "   \n",
    "    d=np.array(train_df)\n",
    "    X_train = d[:,0:]\n",
    "    y_train = d[:,9]\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    correct = 0\n",
    "    correct_sk = 0\n",
    "    for j in range(len(test_df)):\n",
    "        example = test_df.iloc[j]\n",
    "        if classify_example(example, tree)==example[9]: correct+=1\n",
    "        if clf.predict([example])==example[9]: correct_sk+=1\n",
    "    \n",
    "    \n",
    "    my_accuracies.append(correct/len(test_df))\n",
    "    sk_accuracies.append(correct_sk/len(test_df))\n",
    "\n",
    "# print(my_accuracies)\n",
    "glass_mean_accuracy = np.mean(my_accuracies)\n",
    "glass_variance = np.var(my_accuracies)\n",
    "print(\"Glass Mean Accuracy: \",glass_mean_accuracy)\n",
    "print(\"Glass Accucarcy Varianse: \",glass_variance)\n",
    "# print(sk_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f3 <= 2.68  f2 <= 13.78,R  f4 <= 1.36,R  f7 <= 8.93,R  7.0,R  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f4 <= 1.36,R  f7 <= 8.93,R  2.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f4 <= 1.36,R  f9 <= 0.0  5.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f4 <= 1.36,R  f9 <= 0.0  f9 <= 0.34  f6 <= 0.13,R  5.0,R  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f4 <= 1.36,R  f9 <= 0.0  f9 <= 0.34  f6 <= 0.13,R  2.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f4 <= 1.36,R  f9 <= 0.0  f9 <= 0.34  5.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f8 <= 0.0  f6 <= 0.0  6.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f8 <= 0.0  f6 <= 0.0  f9 <= 0.0  7.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f8 <= 0.0  f6 <= 0.0  f9 <= 0.0  2.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f8 <= 0.0  f7 <= 5.87  5.0  \n",
      "f3 <= 2.68  f2 <= 13.78,R  f8 <= 0.0  f7 <= 5.87  7.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f1 <= 1.51589  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f1 <= 1.51589  f5 <= 72.7  3.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f1 <= 1.51589  f5 <= 72.7  f5 <= 72.88  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f1 <= 1.51589  f5 <= 72.7  f5 <= 72.88  f9 <= 0.0  3.0,R  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f1 <= 1.51589  f5 <= 72.7  f5 <= 72.88  f9 <= 0.0  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f7 <= 10.17  f5 <= 72.64  f2 <= 13.99  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f7 <= 10.17  f5 <= 72.64  f2 <= 13.99  f2 <= 14.32  f7 <= 9.65,R  3.0,R  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f7 <= 10.17  f5 <= 72.64  f2 <= 13.99  f2 <= 14.32  f7 <= 9.65,R  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f7 <= 10.17  f5 <= 72.64  f2 <= 13.99  f2 <= 14.32  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f7 <= 10.17  f5 <= 72.64  3.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f7 <= 10.17  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  f4 <= 1.16  f9 <= 0.0  f6 <= 0.54  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  f4 <= 1.16  f9 <= 0.0  f6 <= 0.54  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  f4 <= 1.16  f9 <= 0.0  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  f4 <= 1.16  f9 <= 0.3  f1 <= 1.51926  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  f4 <= 1.16  f9 <= 0.3  f1 <= 1.51926  7.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  f4 <= 1.16  f9 <= 0.3  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f1 <= 1.51694  f6 <= 0.23  f3 <= 3.74  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f5 <= 72.81  f8 <= 0.0  f7 <= 8.6  f9 <= 0.0  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f5 <= 72.81  f8 <= 0.0  f7 <= 8.6  f9 <= 0.0  3.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f5 <= 72.81  f8 <= 0.0  f7 <= 8.6  3.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f5 <= 72.81  f8 <= 0.0  7.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f5 <= 72.81  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f9 <= 0.15  f6 <= 0.54  f5 <= 72.72  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f9 <= 0.15  f6 <= 0.54  f5 <= 72.72  f6 <= 0.38  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f9 <= 0.15  f6 <= 0.54  f5 <= 72.72  f6 <= 0.38  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f9 <= 0.15  f6 <= 0.54  2.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f9 <= 0.15  f2 <= 12.82  1.0  \n",
      "f3 <= 2.68  f4 <= 1.4  f3 <= 3.45  f9 <= 0.15  f2 <= 12.82  2.0  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Node at 0x1a200b86d8>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type Node is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-12eed5b2f97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type Node is not JSON serializable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "r = json.dumps(tree)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tic-Tac-Toe Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tic-Tac-Toe Mean Accuracy:  0.5952960526315789\n",
      "Tic-Tac-Toe Accucarcy Varianse:  0.059650727747960916\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data')\n",
    "\n",
    "my_accuracies = []\n",
    "sk_accuracies = []\n",
    "\n",
    "for i in range(10):\n",
    "    train_df, test_df = train_test_k_fold_split(df, i)\n",
    "    tree = decision_tree_algorithm(train_df)\n",
    "    \n",
    "    correct = 0\n",
    "    correct_sk = 0\n",
    "    for j in range(len(test_df)):\n",
    "        example = test_df.iloc[j]\n",
    "        if classify_example(example, tree)==example[9]: correct+=1\n",
    "    \n",
    "    my_accuracies.append(correct/len(test_df))\n",
    "\n",
    "\n",
    "ttt_mean_accuracy = np.mean(my_accuracies)\n",
    "ttt_variance = np.var(my_accuracies)\n",
    "print(\"Tic-Tac-Toe Mean Accuracy: \",ttt_mean_accuracy)\n",
    "print(\"Tic-Tac-Toe Accucarcy Varianse: \",ttt_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 2**\n",
    "\n",
    "There are two possible sources for class label noise:\n",
    "\n",
    "a) Contradictory examples. The same sample appears more than once and is labeled with a different classification.\n",
    "\n",
    "b) Misclassified examples. A sample is labeled with the wrong class. This type of error is common in situations where different classes of data have similar symptoms.\n",
    "\n",
    "To evaluate the impact of class label noise, you should execute your experiments on both datasets, while various levels of noise are added. Then utilize the designed C4.5 learning algorithm from Question 1 to learn from the noisy datasets and evaluate the impact of class label noise (both Contradictory examples & Misclassified examples).\n",
    "\n",
    "● Note: when creating the noisy datasets, select L% of training data randomly and change them. (Try 10-times-10-fold cross validation to calculate the accuracy/error for each experiment.)\n",
    "\n",
    "a) Plot one figure for each dataset that shows the noise free classification accuracy along with the classification accuracy for the following noise levels: 5%, 10%, and 15%. Plot the two types of noise on one figure.\n",
    "\n",
    "b) How do you explain the effect of noise on the C4.5 method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_misclassified_noise(data, val):    \n",
    "    label_column = data.iloc[:,9]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    for _ in range(int(val*len(data))):\n",
    "        random_index_for_data = np.random.randint(low=0, high=len(data))\n",
    "        random_index_for_unique_labels = np.random.randint(low=0, high=len(unique_classes))\n",
    "        data.iloc[random_index_for_data,9]=unique_classes[random_index_for_unique_labels]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Noise  0.05 Mean : 0.5235930735930736  Var : 0.03895396450591256\n",
      "For Noise  0.1 Mean : 0.4054112554112554  Var : 0.06861851352111092\n",
      "For Noise  0.15 Mean : 0.4391774891774891  Var : 0.04600030921459493\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "\n",
    "accuracies_under_misclassified_noise = []\n",
    "\n",
    "noises = [0.05,0.10,0.15]\n",
    "for noise in noises:\n",
    "    my_accuracies = []\n",
    "    for i in range(10):\n",
    "        \n",
    "        train_df, test_df = train_test_k_fold_split(df, i)\n",
    "        train_df = generate_misclassified_noise(train_df,noise)\n",
    "        tree = decision_tree_algorithm(train_df)\n",
    "\n",
    "        correct = 0\n",
    "        for j in range(len(test_df)):\n",
    "            example = test_df.iloc[j]\n",
    "            if classify_example(example, tree)==example[9]: correct+=1\n",
    "        my_accuracies.append(correct/len(test_df))\n",
    "    print(\"For Noise \",noise,\"Mean :\", np.mean(my_accuracies),\" Var :\",np.var(my_accuracies))\n",
    "    accuracies_under_misclassified_noise.append(np.mean(my_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [glass_mean_accuracy]+accuracies_under_misclassified_noise\n",
    "plt.bar([\"No Noise\",\"5%\",\"10%\",\"15%\"], y)\n",
    "plt.title(\"Percentage of Misclassified Noise vs Accuracy\")\n",
    "plt.xlabel(\"Percentage of Noise\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_contradictory_noise(data, val):    \n",
    "    d=data\n",
    "    label_column = data.iloc[:,9]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    for _ in range(int(val*len(data))):\n",
    "        random_index_for_data = np.random.randint(low=0, high=len(data))\n",
    "        random_index_for_unique_labels = np.random.randint(low=0, high=len(unique_classes))\n",
    "        new_row=data.iloc[random_index_for_data]\n",
    "        new_row[9]=unique_classes[random_index_for_unique_labels]\n",
    "        d=d.append(new_row)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tushar/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Noise  0.05 Mean : 0.48571428571428565  Var : 0.04227450759918293\n",
      "For Noise  0.1 Mean : 0.4807359307359307  Var : 0.06306520679897304\n",
      "For Noise  0.15 Mean : 0.4108225108225108  Var : 0.037186147186147184\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "\n",
    "noises = [0.05,0.10,0.15]\n",
    "\n",
    "accuracies_under_contradictory_noise = []\n",
    "for noise in noises:\n",
    "    my_accuracies = []\n",
    "    for i in range(10):\n",
    "        \n",
    "        train_df, test_df = train_test_k_fold_split(df, i)\n",
    "        train_df = generate_contradictory_noise(train_df,noise)\n",
    "        tree = decision_tree_algorithm(train_df)\n",
    "        correct = 0\n",
    "        for j in range(len(test_df)):\n",
    "            example = test_df.iloc[j]\n",
    "            if classify_example(example, tree)==example[9]: correct+=1\n",
    "        my_accuracies.append(correct/len(test_df))\n",
    "    print(\"For Noise \",noise,\"Mean :\", np.mean(my_accuracies),\" Var :\",np.var(my_accuracies))\n",
    "    accuracies_under_contradictory_noise.append(np.mean(my_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [glass_mean_accuracy]+accuracies_under_contradictory_noise\n",
    "plt.bar([\"No Noise\",\"5%\",\"10%\",\"15%\"], y)\n",
    "plt.title(\"Percentage of Contradictory Noise vs Accuracy\")\n",
    "plt.xlabel(\"Percentage of Noise\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
