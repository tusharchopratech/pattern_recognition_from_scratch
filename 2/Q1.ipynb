{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets Description\n",
    "\n",
    "The UCI Machine Learning Repository is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms.\n",
    "\n",
    "Datasets are available on http://archive.ics.uci.edu/ml/datasets.html For this homework assignment, you need to download the datasets “glass” and “Tic-Tac-Toe Endgame” from the above link. The “glass” dataset is categorical and the “Tic-Tac-Toe” dataset is continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 1**\n",
    "\n",
    "Design a C4.5 decision tree classifier to classify each dataset mentioned above. Report the accuracy based on the 10-times-10-fold cross validation approach (20% of training set as the validation set for every experiment). Report the mean accuracy and the variance of the accuracy for each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node: \n",
    "    def __init__(self, data): \n",
    "        self.data = data \n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(self): \n",
    "        self.root_main = None\n",
    "        self.rules = []\n",
    "    \n",
    "    def build_tree(self, df, root=None, pointer=\"S\", counter=0):\n",
    "\n",
    "        # data preparations\n",
    "        if counter == 0:\n",
    "            global COLUMN_HEADERS, FEATURE_TYPES\n",
    "            COLUMN_HEADERS = df.columns\n",
    "            FEATURE_TYPES = determine_type_of_feature(df)\n",
    "            data = df.values\n",
    "        else:\n",
    "            data = df           \n",
    "\n",
    "        # base cases\n",
    "        if (check_purity(data)):\n",
    "            classification = classify_data(data)\n",
    "            node = Node(classification)\n",
    "            if pointer is \"L\":\n",
    "                root.left=node\n",
    "                root=node\n",
    "            if pointer is \"R\":\n",
    "                root.right=node\n",
    "                root=node\n",
    "            return \n",
    "        # recursive part\n",
    "        else:    \n",
    "            counter += 1\n",
    "\n",
    "            # helper functions \n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, potential_splits)\n",
    "            data_below, data_above = split_data(data, split_column, split_value)\n",
    "\n",
    "            # check for empty data\n",
    "            if len(data_below) == 0 or len(data_above) == 0:\n",
    "                classification = classify_data(data)\n",
    "                node = Node(classification)\n",
    "                if pointer is \"L\":\n",
    "                    root.left=node\n",
    "                    root=node\n",
    "                if pointer is \"R\":\n",
    "                    root.right=node\n",
    "                    root=node\n",
    "                return\n",
    "\n",
    "            # determine question\n",
    "            feature_name = COLUMN_HEADERS[split_column]\n",
    "            type_of_feature = FEATURE_TYPES[split_column]\n",
    "            if type_of_feature == \"continuous\":\n",
    "                question = \"{} <= {}\".format(feature_name, split_value)\n",
    "\n",
    "            # feature is categorical\n",
    "            else:\n",
    "                question = \"{} == {}\".format(feature_name, split_value)\n",
    "\n",
    "            # instantiate sub-tree\n",
    "            if pointer is \"S\":\n",
    "                root=Node(question)\n",
    "                self.root_main = root\n",
    "            else:\n",
    "    #             sub_tree = {question: []}\n",
    "\n",
    "                # find answers (recursion) \n",
    "                node = Node(question)\n",
    "                if pointer is \"L\":\n",
    "                    root.left=node   \n",
    "                    root=node\n",
    "\n",
    "                if pointer is \"R\":\n",
    "                    root.right=node\n",
    "                    root=node\n",
    "\n",
    "            self.build_tree(data_below, root, \"L\", counter)\n",
    "            self.build_tree(data_above, root, \"R\", counter)\n",
    "\n",
    "            return self.root_main\n",
    "         \n",
    "    def convert_tree_to_rules(self, path=[], pathLen=0, status=\"\"):\n",
    "        root = self.root_main\n",
    "        self.get_paths(root,path,pathLen,status)\n",
    "        ar = np.array(self.rules)\n",
    "        for i in range(len(self.rules)):\n",
    "            for j in range(len(self.rules[i])):\n",
    "                if \"R\" in self.rules[i][j]:\n",
    "                    feature_index, comparison_operator, value = self.rules[i][j-1].split(\" \")\n",
    "                    if FEATURE_TYPES[int(feature_index)] == \"continuous\":\n",
    "                        self.rules[i][j-1] = \"{} > {}\".format(feature_index, value) \n",
    "                    else:\n",
    "                        self.rules[i][j-1] = \"{} != {}\".format(feature_index, value) \n",
    "                self.rules[i][j]=self.rules[i][j].replace('R', '')\n",
    "                self.rules[i][j]=self.rules[i][j].replace('L', '')\n",
    "        return self.rules\n",
    "        \n",
    "    def printArray(self, ints, len): \n",
    "        array = []\n",
    "        for i in ints[0 : len]:\n",
    "            array.append(str(i))\n",
    "        self.rules.append(array)\n",
    "    \n",
    "    def get_paths(self, root, path, pathLen, status):\n",
    "\n",
    "        if root is None: \n",
    "            return\n",
    "\n",
    "        if(len(path) > pathLen):  \n",
    "            path[pathLen] = status+str(root.data) \n",
    "        else: \n",
    "            path.append(status+str(root.data))\n",
    "\n",
    "        pathLen = pathLen + 1\n",
    "\n",
    "        if root.left is None and root.right is None: \n",
    "            self.printArray(path, pathLen) \n",
    "        else: \n",
    "            self.get_paths(root.left, path, pathLen, \"L\") \n",
    "            self.get_paths(root.right, path, pathLen, \"R\") \n",
    "\n",
    "    def get_class_of_sample_from_rule(self, rule, sample):\n",
    "        \n",
    "#         sample = [float(val) for val in sample]\n",
    "        sample_class = None\n",
    "        for i in range(len(rule)):\n",
    "            if i < len(rule) - 1:\n",
    "                feature_index, comparison_operator, value = rule[i].split(\" \")\n",
    "                if FEATURE_TYPES[int(feature_index)] == \"continuous\":\n",
    "                    if comparison_operator == \"<=\":\n",
    "                        if not float(sample[int(feature_index)]) <= float(value):\n",
    "                            break\n",
    "                    elif comparison_operator == \">\":\n",
    "                        if not float(sample[int(feature_index)]) > float(value):\n",
    "                            break\n",
    "                else:\n",
    "                    if comparison_operator == \"==\":\n",
    "                        if not sample[int(feature_index)] == value:\n",
    "                            break\n",
    "                    elif comparison_operator == \"!=\":\n",
    "                        if not sample[int(feature_index)] is not value:\n",
    "                            break\n",
    "            else:\n",
    "                sample_class = rule[len(rule)-1]\n",
    "                \n",
    "        return sample_class\n",
    "            \n",
    "    def prune_rule(self, rule, validation_data):\n",
    "        \n",
    "        base_rule = rule\n",
    "        old_accuracy = 0\n",
    "        new_rule = rule\n",
    "        new_accuracy = 0.0\n",
    "        base_accuracy = 0\n",
    "        \n",
    "        flag = 1\n",
    "        for total_rule_elements in range(len(rule)-1, 1, -1):\n",
    "            \n",
    "            my_rule = rule[:total_rule_elements]\n",
    "            my_rule.append(rule[len(rule)-1])\n",
    "            accuracy = 0\n",
    "\n",
    "            for i in range(len(validation_data)):\n",
    "                predict_class = self.get_class_of_sample_from_rule(my_rule, validation_data[i])\n",
    "                if predict_class == str(validation_data[i][9]):\n",
    "                    accuracy +=1\n",
    "            if flag == 1:\n",
    "                base_accuracy = accuracy/len(validation_data)\n",
    "                old_accuracy=base_accuracy\n",
    "                new_accuracy=base_accuracy\n",
    "                new_rule = my_rule\n",
    "                flag=0\n",
    "#                 print(\"\")\n",
    "#                 print(\"Base: \",base_accuracy,\" : \", base_rule)\n",
    "            else:\n",
    "                new_accuracy = accuracy/len(validation_data)\n",
    "#                 print(\"Pruned: \",new_accuracy,\" : \", my_rule)\n",
    "                if new_accuracy == 1.0:\n",
    "#                     new_accuracy=old_accuracy\n",
    "                    return base_rule, base_accuracy, new_rule, old_accuracy\n",
    "                elif new_accuracy > old_accuracy:\n",
    "                    new_rule = my_rule\n",
    "                    old_accuracy = new_accuracy\n",
    "                      \n",
    "        return base_rule, base_accuracy, new_rule, new_accuracy\n",
    "    \n",
    "    def prune_rule2(self, rule, validation_data):\n",
    "        \n",
    "        base_rule = rule\n",
    "        old_accuracy = 0\n",
    "        new_rule = rule\n",
    "        new_accuracy = 0.0\n",
    "        base_accuracy = 0\n",
    "        \n",
    "    \n",
    "        flag = 1\n",
    "        for total_rule_elements in range(len(rule)-1, 3, -1):\n",
    "            \n",
    "            my_rule = rule[:total_rule_elements]\n",
    "            my_rule.append(rule[len(rule)-1])\n",
    "            accuracy = 0\n",
    "\n",
    "            for i in range(len(validation_data)):\n",
    "                predict_class = self.get_class_of_sample_from_rule(my_rule, validation_data[i])\n",
    "                if predict_class == str(validation_data[i][9]):\n",
    "                    accuracy +=1\n",
    "            if flag == 1:\n",
    "                base_accuracy = accuracy/len(validation_data)\n",
    "                old_accuracy=base_accuracy\n",
    "                new_accuracy=base_accuracy\n",
    "                new_rule = my_rule\n",
    "                flag=0\n",
    "#                 print(\"\")\n",
    "#                 print(\"Base: \",base_accuracy,\" : \", base_rule)\n",
    "            else:\n",
    "                new_accuracy = accuracy/len(validation_data)\n",
    "#                 print(\"Pruned: \",new_accuracy,\" : \", my_rule)\n",
    "                if new_accuracy == 1.0:\n",
    "#                     new_accuracy=old_accuracy\n",
    "                    return base_rule, base_accuracy, new_rule, old_accuracy\n",
    "                elif new_accuracy > old_accuracy:\n",
    "                    new_rule = my_rule\n",
    "                    old_accuracy = new_accuracy\n",
    "                      \n",
    "        return base_rule, base_accuracy, new_rule, new_accuracy\n",
    "    \n",
    "    def prune_tree(self, validation_data):\n",
    "        \n",
    "        self.convert_tree_to_rules()\n",
    "#         for rule in self.rules:\n",
    "#             print(rule)\n",
    "        validation_data=validation_data.values\n",
    "        new_rules = []\n",
    "    \n",
    "        for i, rule in enumerate(self.rules):\n",
    "            rule_label = rule[len(rule)-1]    \n",
    "            if isinstance(validation_data[:,-1][0],float):\n",
    "                filtered_validation_data = validation_data[np.where(validation_data[:,-1] == float(rule_label))]\n",
    "            else:\n",
    "                filtered_validation_data = validation_data[np.where(validation_data[:,-1] == rule_label)]\n",
    "            \n",
    "            if len(filtered_validation_data)>0:\n",
    "                old_rule, old_accurcay, new_rule, new_accuracy = self.prune_rule(rule, filtered_validation_data)\n",
    "                new_rule = [new_accuracy] + new_rule\n",
    "                new_rules.append(new_rule)\n",
    "        \n",
    "        self.rules = new_rules\n",
    "        self.rules.sort(key=lambda x: x[0])\n",
    "        self.rules = self.rules[::-1]\n",
    "    \n",
    "    def prune_tree2(self, validation_data):\n",
    "        \n",
    "        self.convert_tree_to_rules()\n",
    "#         for rule in self.rules:\n",
    "#             print(rule)\n",
    "        validation_data=validation_data.values\n",
    "        new_rules = []\n",
    "    \n",
    "        for i, rule in enumerate(self.rules):\n",
    "            rule_label = rule[len(rule)-1]    \n",
    "            old_rule, old_accurcay, new_rule, new_accuracy = self.prune_rule(rule, validation_data)\n",
    "            new_rule = [new_accuracy] + new_rule\n",
    "            new_rules.append(new_rule)\n",
    "        \n",
    "        self.rules = new_rules\n",
    "        self.rules.sort(key=lambda x: x[0])\n",
    "        self.rules = self.rules[::-1]\n",
    "    \n",
    "    def get_rules(self): \n",
    "        self.rules = [val[1:] for val in self.rules]\n",
    "        return self.rules\n",
    "    \n",
    "    def predict_class(self, sample):\n",
    "        sample_class = None\n",
    "        for rule in self.rules:\n",
    "            sample_class = self.get_class_of_sample_from_rule(rule,sample)\n",
    "            if sample_class is not None:\n",
    "                break\n",
    "        return sample_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_k_fold_split(df, fold):\n",
    "    indices = df.index.tolist()\n",
    "#     np.random.shuffle(indices)\n",
    "    low = int((fold/10)*len(indices))\n",
    "    high = int(((fold+1)/10)*len(indices))\n",
    "    test_indices=indices[low:high]\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_and_validation(df, division):\n",
    "    indices = df.index.tolist()\n",
    "#     np.random.shuffle(indices)\n",
    "    validation_indices=indices[int((1-division)*len(indices)):]\n",
    "    validation_df = df.loc[validation_indices]\n",
    "    train_df = df.drop(validation_indices)\n",
    "    return train_df, validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n",
      "0.6190476190476191\n",
      "0.6190476190476191\n",
      "0.6363636363636364\n",
      "0.5714285714285714\n",
      "0.8095238095238095\n",
      "0.6818181818181818\n",
      "0.5238095238095238\n",
      "0.5714285714285714\n",
      "0.5454545454545454\n",
      "Glass Mean Accuracy:  0.6244588744588745\n",
      "Glass Accucarcy Varianse:  0.006151730664717679\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "df.columns = [i for i in range(len(df.columns))]\n",
    "df=df.sample(frac=1)\n",
    "# np.random.seed(0) \n",
    "\n",
    "my_accuracies = []\n",
    "for i in range(10):\n",
    "    decision_tree = DecisionTree()\n",
    "    train_df, test_df = train_test_k_fold_split(df, i)\n",
    "    train_data, validation_data=split_training_and_validation(train_df, 0.2)\n",
    "    decision_tree.build_tree(train_data)\n",
    "    decision_tree.prune_tree(validation_data)\n",
    "    decision_tree.get_rules()\n",
    "    \n",
    "    correct = 0\n",
    "    for j in range(len(test_df)):\n",
    "        example = test_df.iloc[j]\n",
    "        if decision_tree.predict_class(example) is not None and float(decision_tree.predict_class(example))==example[9]: correct+=1\n",
    "    my_accuracies.append(correct/len(test_df))\n",
    "   \n",
    "glass_mean_accuracy = np.mean(my_accuracies)\n",
    "glass_variance = np.var(my_accuracies)\n",
    "print(\"Glass Mean Accuracy: \",glass_mean_accuracy)\n",
    "print(\"Glass Accucarcy Varianse: \",glass_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7894736842105263\n",
      "0.7604166666666666\n",
      "0.75\n",
      "0.8\n",
      "0.7916666666666666\n",
      "0.7395833333333334\n",
      "0.7894736842105263\n",
      "0.8020833333333334\n",
      "0.75\n",
      "0.8125\n",
      "Tic-Tac-Toe Mean Accuracy:  0.7785197368421053\n",
      "Tic-Tac-Toe Accucarcy Varianse:  0.0006054638205986458\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data')\n",
    "df.columns = [i for i in range(len(df.columns))]\n",
    "df=df.sample(frac=1)\n",
    "# np.random.seed(2) \n",
    "my_accuracies = []\n",
    "for i in range(10):\n",
    "    \n",
    "    decision_tree = DecisionTree()\n",
    "    train_df, test_df = train_test_k_fold_split(df, i)\n",
    "    train_data, validation_data=split_training_and_validation(train_df, 0.2)\n",
    "    decision_tree.build_tree(train_data)\n",
    "    decision_tree.prune_tree(validation_data)\n",
    "    decision_tree.get_rules()\n",
    "    \n",
    "    correct = 0\n",
    "    for j in range(len(test_df)):\n",
    "        example = test_df.iloc[j]\n",
    "        if decision_tree.predict_class(example) is not None and decision_tree.predict_class(example)==example[9]: correct+=1\n",
    "    print(correct/len(test_df))\n",
    "    \n",
    "    my_accuracies.append(correct/len(test_df))\n",
    "\n",
    "ttt_mean_accuracy = np.mean(my_accuracies)\n",
    "ttt_variance = np.var(my_accuracies)\n",
    "print(\"Tic-Tac-Toe Mean Accuracy: \",ttt_mean_accuracy)\n",
    "print(\"Tic-Tac-Toe Accucarcy Varianse: \",ttt_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Question 2**\n",
    "\n",
    "There are two possible sources for class label noise:\n",
    "\n",
    "a) Contradictory examples. The same sample appears more than once and is labeled with a different classification.\n",
    "\n",
    "b) Misclassified examples. A sample is labeled with the wrong class. This type of error is common in situations where different classes of data have similar symptoms.\n",
    "\n",
    "To evaluate the impact of class label noise, you should execute your experiments on both datasets, while various levels of noise are added. Then utilize the designed C4.5 learning algorithm from Question 1 to learn from the noisy datasets and evaluate the impact of class label noise (both Contradictory examples & Misclassified examples).\n",
    "\n",
    "● Note: when creating the noisy datasets, select L% of training data randomly and change them. (Try 10-times-10-fold cross validation to calculate the accuracy/error for each experiment.)\n",
    "\n",
    "a) Plot one figure for each dataset that shows the noise free classification accuracy along with the classification accuracy for the following noise levels: 5%, 10%, and 15%. Plot the two types of noise on one figure.\n",
    "\n",
    "b) How do you explain the effect of noise on the C4.5 method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glass Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_misclassified_noise(data, val):    \n",
    "    label_column = data.iloc[:,9]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    for _ in range(int(val*len(data))):\n",
    "        random_index_for_data = np.random.randint(low=0, high=len(data))\n",
    "        random_index_for_unique_labels = np.random.randint(low=0, high=len(unique_classes))\n",
    "        data.iloc[random_index_for_data,9]=unique_classes[random_index_for_unique_labels]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Noise  5.0 %  Mean : 0.6383116883116883  Var : 0.006885599970015555\n",
      "For Noise  10.0 %  Mean : 0.5768398268398268  Var : 0.012401613537977176\n",
      "For Noise  15.0 %  Mean : 0.5266233766233765  Var : 0.016851305260396167\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data')\n",
    "df=df.drop(df.columns[0], axis=1)\n",
    "df.columns = [i for i in range(len(df.columns))]\n",
    "np.random.seed(2) \n",
    "\n",
    "accuracies_under_misclassified_noise = []\n",
    "noises = [0.05,0.10,0.15]\n",
    "for noise in noises:\n",
    "    my_accuracies = []\n",
    "    for i in range(10):\n",
    "\n",
    "        decision_tree = DecisionTree()\n",
    "        train_df, test_df = train_test_k_fold_split(df, i)\n",
    "        train_df = generate_misclassified_noise(train_df,noise)\n",
    "        train_data, validation_data=split_training_and_validation(train_df, 0.2)\n",
    "        decision_tree.build_tree(train_data)\n",
    "        decision_tree.prune_tree(validation_data)\n",
    "        decision_tree.get_rules()\n",
    "\n",
    "        correct = 0\n",
    "        for j in range(len(test_df)):\n",
    "            example = test_df.iloc[j]\n",
    "            if decision_tree.predict_class(example) is not None and float(decision_tree.predict_class(example))==example[9]: correct+=1\n",
    "#         print(correct/len(test_df))\n",
    "        my_accuracies.append(correct/len(test_df))\n",
    "    print(\"For Noise \",noise*100,\"%  Mean :\", np.mean(my_accuracies),\" Var :\",np.var(my_accuracies))\n",
    "    accuracies_under_misclassified_noise.append(np.mean(my_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [glass_mean_accuracy]+accuracies_under_misclassified_noise\n",
    "plt.bar([\"No Noise\",\"5%\",\"10%\",\"15%\"], y)\n",
    "plt.title(\"Percentage of Misclassified Noise vs Accuracy\")\n",
    "plt.xlabel(\"Percentage of Noise\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_contradictory_noise(data, val):    \n",
    "    d=data\n",
    "    label_column = data.iloc[:,9]\n",
    "    unique_classes = np.unique(label_column)\n",
    "    for _ in range(int(val*len(data))):\n",
    "        random_index_for_data = np.random.randint(low=0, high=len(data))\n",
    "        random_index_for_unique_labels = np.random.randint(low=0, high=len(unique_classes))\n",
    "        new_row=data.iloc[random_index_for_data]\n",
    "        new_row[9]=unique_classes[random_index_for_unique_labels]\n",
    "        d=d.append(new_row)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Noise  0.05 Mean : 0.9163596491228072  Var : 0.0015883945060018462\n",
      "For Noise  0.1 Mean : 0.9039473684210526  Var : 0.0015347943598030167\n",
      "For Noise  0.15 Mean : 0.8944627192982455  Var : 0.002147550808902739\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/tic-tac-toe/tic-tac-toe.data')\n",
    "df.columns = [i for i in range(len(df.columns))]\n",
    "# np.random.seed(1) \n",
    "np.random.seed(seed=None)\n",
    "\n",
    "noises = [0.05,0.10,0.15]\n",
    "accuracies_under_contradictory_noise = []\n",
    "for noise in noises:\n",
    "\n",
    "    my_accuracies = []\n",
    "    for i in range(10):\n",
    "        decision_tree = DecisionTree()\n",
    "        train_df, test_df = train_test_k_fold_split(df, i)\n",
    "        train_df = generate_contradictory_noise(train_df,noise)\n",
    "        train_data, validation_data=split_training_and_validation(train_df, 0.2)\n",
    "        decision_tree.build_tree(train_data)\n",
    "        decision_tree.prune_tree(validation_data)\n",
    "        decision_tree.get_rules()\n",
    "\n",
    "        correct = 0\n",
    "        for j in range(len(test_df)):\n",
    "            example = test_df.iloc[j]\n",
    "            if decision_tree.predict_class(example) is not None and decision_tree.predict_class(example)==example[9]: correct+=1\n",
    "\n",
    "        my_accuracies.append(correct/len(test_df))\n",
    "    print(\"For Noise \",noise,\"Mean :\", np.mean(my_accuracies),\" Var :\",np.var(my_accuracies))\n",
    "    accuracies_under_contradictory_noise.append(np.mean(my_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = [ttt_mean_accuracy]+accuracies_under_contradictory_noise\n",
    "plt.bar([\"No Noise\",\"5%\",\"10%\",\"15%\"], y)\n",
    "plt.title(\"Percentage of Contradictory Noise vs Accuracy\")\n",
    "plt.xlabel(\"Percentage of Noise\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
